\documentclass{article}
\usepackage{amsmath}
\usepackage[T2A]{fontenc}
\usepackage{hyphenat}
\hyphenation{ма-те-ма-ти-ка вос-ста-нав-ли-вать}
\usepackage[english, russian]{babel}
\usepackage[T1]{tipa}
\usepackage{tipx}

\newcommand{\mathnrleg}{\textnormal{\textnrleg}}

\title{tprlab1}
\author{author}
\date{March 2023}

\begin{document}
\maketitle

\section{Задача}
Пусть Y = \{0, 1\}, D = [0, 1], l(x, y) = $|x - y|$. Докажите, что общие потери алгоритма экспоненциального взвешивания экспертных решений не меньше общих потерь
лучшего эксперта.

\section{Известно}
{\Large
$\hat{L}_t = \sum_{i=1}^N l(x,y) = \sum_{i=1}^N |\hat{p}_t - y_t|$ - потери алгоритма \\\\
$L_{i,t} = \sum_{i=1}^N l(x_i,y) = \sum_{i=1}^N |\hat{f}_{i,t} - y_t|$ - потери эксперта \\\\
$\hat{p}_t = \frac{\sum_{i=1}^N w_{i,t-1} \cdot f_{i,t}}{\sum_{i=1}^N w_{i,t-1}} = \frac{\sum_{i=1}^{N}\, e^{-nL_{i,t-1}}f_{i,t}}{\sum_{i=1}^{N}\, e^{-nL_{i,t-1}}}$ - предсказание \\\\
$W_t = \sum_{i=1}^N w_{i,t} = \sum_{i=1}^{T}\, e^{-nL_{i,t}}$ - веса экспертов \\\\
$ln\frac{W_t}{W_{t-1}} = ln\sum_{i=1}^N p_k(t-1)e^{-\mathnrleg|f_{i,t}-y_t|} \\\\$
$ln\frac{W_t}{W_{0}} = ln(\sum_{i=1}^N e^{-nL_{i,t}})-lnN$
}

\section{Решение}
Общие потери лучшего эксперта обозначим как:

$$i^\star = \arg\min_{i=1}^N L_{i,T}$$

Для доказательства того, что общие потери алгоритма не меньше общих потерь лучшего эксперта, воспользуемся леммой.
Лемма: При оюбых неотрицательных весах экспертов $w_1, w_2, ..., w_N$, и их неотрицательных значений  $p_1, p_2, ..., p_N$ имеем
$$
\frac{\sum_{i=1}^N w_i\cdot f_i}{\sum_{i=1}^N w_i} \geq \min_{i=1}^N f_i
$$
Доказательство леммы: \\\\
Обозначим $i^\star = \arg\min_{i=1}^N l_i$. Тогда
$$
\frac{\sum_{i=1}^N w_i\cdot p_i}{\sum_{i=1}^N w_i} \geq \frac{w_{i^\star} \cdot p_{i^\star}}{\sum_{i=1}^N w_i} \geq \frac{w_{i^\star} \cdot \min_{i=1}^N p_i}{\sum_{i=1}^N w_i} \geq \min_{i=1}^N p_i
$$
where the first inequality follows from the fact that the numerator is a weighed average of non-negative numbers, and the second inequality follows from the choice of $i^\star$. \\

Доказательство теоремы: \\\\
$
\hat{L}_t = \sum_{i=1}^N l(\hat{p}_t, y_t) = \sum_{i=1}^N |\hat{p}_t - y_t| = \sum_{i=1}^N \left|\frac{\sum_{i=1}^N w_i\cdot f_i}{\sum_{i=1}^N w_i} - y_t\right| \geq \\
\geq \sum_{i=1}^N \min_{i=1}^N l(f_{i,t},y_t) = \min_{i=1}^N \sum_{t=1}^T \left|f_{i,t} - y_t\right| = L_{i^\star,t} \\\\
$
Таким образом мы показали, что общие потери алгоритма по крайней мере не меньше общих потерь эксперта.

\end{document}
